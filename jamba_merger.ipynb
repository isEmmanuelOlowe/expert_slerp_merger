{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"ai21labs/Jamba-v0.1\"\n",
    "\n",
    "temp_dir = \"/home/emmanuel/Documents/moe-bamba/models\"\n",
    "model_name = model_name_or_path.split(\"/\")[-1]\n",
    "target_dir = f\"{temp_dir}/{model_name}\"\n",
    "save_dir   =  \"/home/emmanuel/Documents/moe-bamba/models/Jamba-8xMoE_slerp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (4.40.0.dev0)\n",
      "Requirement already satisfied: torch in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: safetensors in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/emmanuel/miniconda3/envs/mamba/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/Documents/moe-bamba/models\n",
      "--2024-03-29 22:58:39--  https://huggingface.co/ai21labs/Jamba-v0.1/resolve/main/config.json\n",
      "Resolving huggingface.co (huggingface.co)... 3.162.20.5, 3.162.20.50, 3.162.20.118, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.162.20.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1310 (1.3K) [text/plain]\n",
      "Saving to: ‘Jamba-v0.1/config.json’\n",
      "\n",
      "Jamba-v0.1/config.j 100%[===================>]   1.28K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-29 22:58:40 (1.34 GB/s) - ‘Jamba-v0.1/config.json’ saved [1310/1310]\n",
      "\n",
      "--2024-03-29 22:58:40--  https://huggingface.co/ai21labs/Jamba-v0.1/resolve/main/model.safetensors.index.json\n",
      "Resolving huggingface.co (huggingface.co)... 3.162.20.5, 3.162.20.118, 3.162.20.54, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.162.20.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 107400 (105K) [text/plain]\n",
      "Saving to: ‘Jamba-v0.1/model.safetensors.index.json’\n",
      "\n",
      "Jamba-v0.1/model.sa 100%[===================>] 104.88K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-03-29 22:58:40 (713 KB/s) - ‘Jamba-v0.1/model.safetensors.index.json’ saved [107400/107400]\n",
      "\n",
      "--2024-03-29 22:58:40--  https://huggingface.co/ai21labs/Jamba-v0.1/resolve/main/generation_config.json\n",
      "Resolving huggingface.co (huggingface.co)... 3.162.20.54, 3.162.20.118, 3.162.20.5, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.162.20.54|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 137 [text/plain]\n",
      "Saving to: ‘Jamba-v0.1/generation_config.json’\n",
      "\n",
      "Jamba-v0.1/generati 100%[===================>]     137  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-29 22:58:41 (176 MB/s) - ‘Jamba-v0.1/generation_config.json’ saved [137/137]\n",
      "\n",
      "model-00001-of-00021.safetensors already exists\n",
      "model-00002-of-00021.safetensors already exists\n",
      "model-00003-of-00021.safetensors already exists\n",
      "model-00004-of-00021.safetensors already exists\n",
      "model-00005-of-00021.safetensors already exists\n",
      "model-00006-of-00021.safetensors already exists\n",
      "model-00007-of-00021.safetensors already exists\n",
      "model-00008-of-00021.safetensors already exists\n",
      "model-00009-of-00021.safetensors already exists\n",
      "model-00010-of-00021.safetensors already exists\n",
      "model-00011-of-00021.safetensors already exists\n",
      "model-00012-of-00021.safetensors already exists\n",
      "model-00013-of-00021.safetensors already exists\n",
      "model-00014-of-00021.safetensors already exists\n",
      "model-00015-of-00021.safetensors already exists\n",
      "model-00016-of-00021.safetensors already exists\n",
      "model-00017-of-00021.safetensors already exists\n",
      "model-00018-of-00021.safetensors already exists\n",
      "model-00019-of-00021.safetensors already exists\n",
      "model-00020-of-00021.safetensors already exists\n",
      "model-00021-of-00021.safetensors already exists\n"
     ]
    }
   ],
   "source": [
    "%cd {temp_dir}\n",
    "import os\n",
    "save_model_dir = model_name.split('/')[-1]\n",
    "!mkdir -p {save_model_dir}\n",
    "\n",
    "!wget https://huggingface.co/{model_name_or_path}/resolve/main/config.json -O {save_model_dir}/config.json\n",
    "!wget https://huggingface.co/{model_name_or_path}/resolve/main/model.safetensors.index.json -O {save_model_dir}/model.safetensors.index.json\n",
    "!wget https://huggingface.co/{model_name_or_path}/resolve/main/generation_config.json -O {save_model_dir}/generation_config.json\n",
    "\n",
    "for i in range(1,22):\n",
    "    file_count_str = str(i).zfill(5)\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(f\"{save_model_dir}/model-{file_count_str}-of-00021.safetensors\"):\n",
    "        !wget https://huggingface.co/{model_name_or_path}/resolve/main/model-{file_count_str}-of-00021.safetensors?download=true -O {save_model_dir}/model-{file_count_str}-of-00021.safetensors\n",
    "    else:\n",
    "        print(f\"model-{file_count_str}-of-00021.safetensors already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/Documents/moe-bamba/models\n",
      "Divisor: 4\n",
      "num_layer_keys 32\n",
      "starting layer: 0\n",
      "Loading Tensors  model-00001-of-00021.safetensors\n",
      "merging expert 0 to model.layers.0.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.0.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.0.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00001.safetensors\n",
      "starting layer: 1\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "Loading Tensors  model-00001-of-00021.safetensors\n",
      "merging expert 0 to model.layers.1.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.1.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.1.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.1.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.1.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.1.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "merging expert 10 to model.layers.1.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "Loading Tensors  model-00001-of-00021.safetensors\n",
      "merging expert 10 to model.layers.1.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "merging expert 10 to model.layers.1.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.1.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.1.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.1.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.1.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.1.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.1.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.1.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.1.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.1.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.1.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.1.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.1.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.1.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.1.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.1.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.1.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.1.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.1.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.1.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00001-of-00021.safetensors\n",
      "merging expert 2 to model.layers.1.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.1.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.1.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.1.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.1.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.1.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.1.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.1.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.1.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.1.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.1.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.1.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.1.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.1.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.1.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.1.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.1.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.1.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.1.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.1.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.1.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.1.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.1.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.1.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.1.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.1.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.1.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.1.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.1.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.1.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.1.moe.router.weight\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00002.safetensors\n",
      "starting layer: 2\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "merging expert 0 to model.layers.2.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.2.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.2.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00003.safetensors\n",
      "starting layer: 3\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "merging expert 0 to model.layers.3.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.3.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.3.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.3.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.3.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.3.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "merging expert 10 to model.layers.3.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.3.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.3.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.3.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.3.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.3.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.3.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.3.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.3.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.3.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.3.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.3.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.3.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.3.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.3.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.3.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.3.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.3.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.3.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.3.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.3.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.3.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "merging expert 2 to model.layers.3.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.3.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.3.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.3.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.3.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.3.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.3.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.3.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.3.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.3.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.3.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.3.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.3.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.3.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "merging expert 6 to model.layers.3.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.3.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.3.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.3.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.3.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.3.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.3.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.3.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.3.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.3.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.3.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.3.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.3.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.3.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.3.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.3.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00002-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.3.moe.router.weight\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00004.safetensors\n",
      "starting layer: 4\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "merging expert 0 to model.layers.4.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.4.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.4.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00005.safetensors\n",
      "starting layer: 5\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "merging expert 0 to model.layers.5.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.5.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.5.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.5.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.5.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.5.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "merging expert 10 to model.layers.5.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.5.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.5.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.5.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.5.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.5.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.5.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.5.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.5.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.5.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.5.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.5.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.5.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.5.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.5.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.5.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.5.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.5.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.5.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.5.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.5.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.5.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.15.up_proj.weight\n",
      "merging expert 2 to model.layers.5.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "merging expert 2 to model.layers.5.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "merging expert 2 to model.layers.5.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.5.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.5.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.5.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.5.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.5.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.5.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.5.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.5.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.5.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.5.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.5.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.5.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.5.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.5.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.5.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.5.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.5.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.5.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.5.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.5.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.5.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.5.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.5.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.5.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.5.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.5.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.5.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00003-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.5.moe.router.weight\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00006.safetensors\n",
      "starting layer: 6\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "Loading Tensors  model-00004-of-00021.safetensors\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "merging expert 0 to model.layers.6.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.6.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.6.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00007.safetensors\n",
      "starting layer: 7\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "merging expert 0 to model.layers.7.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.7.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.7.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.7.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.7.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.7.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.7.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.7.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.7.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.7.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.7.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.7.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.7.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.7.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.11.up_proj.weight\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "merging expert 12 to model.layers.7.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "merging expert 12 to model.layers.7.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "merging expert 12 to model.layers.7.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.7.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.7.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.7.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.7.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.7.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.7.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.7.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.7.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.7.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.7.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.7.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00005-of-00021.safetensors\n",
      "merging expert 2 to model.layers.7.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.7.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.7.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.7.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.7.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.7.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.7.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.7.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.7.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.7.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.7.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.7.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.7.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.7.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.7.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.7.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.7.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.7.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.7.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.7.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.7.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.7.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.7.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.7.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.7.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.7.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.7.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.7.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.7.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.7.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.7.moe.router.weight\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00008.safetensors\n",
      "starting layer: 8\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "merging expert 0 to model.layers.8.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.8.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.8.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00009.safetensors\n",
      "starting layer: 9\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "merging expert 0 to model.layers.9.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.9.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.9.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.9.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.9.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.9.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "merging expert 10 to model.layers.9.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.9.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.9.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.9.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.9.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.9.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.9.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.9.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.9.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.9.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.9.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.9.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.9.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.9.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.9.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.9.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.9.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.9.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.9.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.9.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.9.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.9.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "merging expert 2 to model.layers.9.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.9.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.9.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.9.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.9.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.9.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.9.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.9.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.9.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.9.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.9.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.9.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.9.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.9.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.9.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.9.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.9.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.9.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.9.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.9.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.9.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.9.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.9.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.9.moe.experts.7.up_proj.weight\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "merging expert 8 to model.layers.9.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.9.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.9.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.9.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.9.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.9.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00006-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.9.moe.router.weight\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00010.safetensors\n",
      "starting layer: 10\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "merging expert 0 to model.layers.10.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.10.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.10.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00011.safetensors\n",
      "starting layer: 11\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "merging expert 0 to model.layers.11.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.11.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.11.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.11.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.11.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.11.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "merging expert 10 to model.layers.11.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.11.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.11.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.11.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.11.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.11.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.11.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.11.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.11.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.11.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.11.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.11.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.11.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.11.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.11.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.11.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.11.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.11.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.11.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.11.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.11.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.11.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "merging expert 2 to model.layers.11.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.11.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.11.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.11.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.11.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.11.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.11.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.3.gate_proj.weight\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "merging expert 3 to model.layers.11.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.11.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.11.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.11.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.11.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.11.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.11.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.11.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.11.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.11.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.11.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.11.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.11.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.11.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.11.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.11.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.11.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.11.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.11.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.11.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.11.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.11.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.11.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00007-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.11.moe.router.weight\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00012.safetensors\n",
      "starting layer: 12\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "merging expert 0 to model.layers.12.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.12.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.12.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00013.safetensors\n",
      "starting layer: 13\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "Loading Tensors  model-00009-of-00021.safetensors\n",
      "merging expert 0 to model.layers.13.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.13.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.13.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.13.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.13.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.13.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.13.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.13.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.13.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.13.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.13.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.13.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.13.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.13.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.13.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.13.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.13.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.13.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.13.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.13.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "merging expert 14 to model.layers.13.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.13.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.13.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.13.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.13.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.13.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.13.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.13.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00009-of-00021.safetensors\n",
      "merging expert 2 to model.layers.13.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.13.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.13.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.13.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.13.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.13.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.13.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.13.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.13.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.13.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.13.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.13.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.13.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.13.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.13.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.13.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.13.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.13.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.13.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.13.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.13.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.13.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.13.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.13.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.13.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.13.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.13.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.13.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.13.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.13.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00008-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.13.moe.router.weight\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00014.safetensors\n",
      "starting layer: 14\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "merging expert 0 to model.layers.14.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.14.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.14.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00015.safetensors\n",
      "starting layer: 15\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "merging expert 0 to model.layers.15.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.15.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.15.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.15.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.15.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.15.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "merging expert 10 to model.layers.15.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.15.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.15.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.15.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.15.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.15.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.15.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.15.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.15.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.15.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.15.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.15.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.15.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.15.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.15.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.15.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.15.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.15.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.15.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.15.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.15.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.15.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "merging expert 2 to model.layers.15.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.15.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.15.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.15.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.15.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.15.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.15.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.15.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.15.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.15.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.15.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.15.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.15.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.15.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.15.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.15.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.15.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.15.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.15.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.15.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.15.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.15.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.15.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.15.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.15.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.15.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.15.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.15.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.15.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "merging expert 9 to model.layers.15.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00010-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.15.moe.router.weight\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00016.safetensors\n",
      "starting layer: 16\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "merging expert 0 to model.layers.16.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.16.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.16.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00017.safetensors\n",
      "starting layer: 17\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "merging expert 0 to model.layers.17.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.17.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.17.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.17.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.17.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.17.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "merging expert 10 to model.layers.17.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.17.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.17.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.17.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.17.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.17.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.17.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.17.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.17.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.17.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.17.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.17.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.17.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.17.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.17.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.17.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.17.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.17.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.17.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.17.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.17.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.17.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "merging expert 2 to model.layers.17.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.17.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.17.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.17.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.17.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.17.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.17.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.17.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.17.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.17.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.17.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "merging expert 5 to model.layers.17.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "merging expert 5 to model.layers.17.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "merging expert 5 to model.layers.17.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.17.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.17.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.17.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.17.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.17.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.17.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.17.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.17.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.17.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.17.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.17.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.17.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.17.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.17.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.17.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.17.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00011-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.17.moe.router.weight\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00018.safetensors\n",
      "starting layer: 18\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "merging expert 0 to model.layers.18.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.18.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.18.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00019.safetensors\n",
      "starting layer: 19\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "merging expert 0 to model.layers.19.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.19.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.19.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00013-of-00021.safetensors\n",
      "merging expert 1 to model.layers.19.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.19.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.19.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.19.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.19.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.19.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.19.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.19.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.19.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.19.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.19.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.19.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.19.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.19.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.19.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.19.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.19.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.19.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.19.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.19.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "merging expert 15 to model.layers.19.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.19.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.19.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.19.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.19.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00013-of-00021.safetensors\n",
      "merging expert 2 to model.layers.19.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.19.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.19.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.19.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.19.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.19.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.19.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.19.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.19.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.19.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.19.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.19.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.19.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.19.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.19.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.19.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.19.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.19.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.19.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.19.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.19.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.19.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.19.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.19.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.19.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.19.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.19.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.19.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.19.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.19.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00012-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.19.moe.router.weight\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00020.safetensors\n",
      "starting layer: 20\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "merging expert 0 to model.layers.20.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.20.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.20.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00021.safetensors\n",
      "starting layer: 21\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "merging expert 0 to model.layers.21.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.21.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.21.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.21.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.21.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.21.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.21.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.21.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.21.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "merging expert 11 to model.layers.21.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.21.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.21.moe.experts.11.down_proj.weight\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "merging expert 11 to model.layers.21.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.11.gate_proj.weight\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "merging expert 11 to model.layers.21.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.21.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.21.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.21.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.21.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.21.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.21.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.21.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.21.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.21.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.21.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.21.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.21.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.21.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.21.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00014-of-00021.safetensors\n",
      "merging expert 2 to model.layers.21.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.21.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.21.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.21.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.21.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.21.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.21.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.21.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.21.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.21.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.21.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.21.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.21.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.21.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.21.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.21.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.21.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.21.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.21.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.21.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.21.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.21.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.21.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.21.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.21.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.21.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.21.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.21.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.21.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.21.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.21.moe.router.weight\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00022.safetensors\n",
      "starting layer: 22\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "merging expert 0 to model.layers.22.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.22.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.22.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00023.safetensors\n",
      "starting layer: 23\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "merging expert 0 to model.layers.23.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.23.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.23.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.23.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.23.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.23.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "merging expert 10 to model.layers.23.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.23.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.23.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.23.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.23.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.23.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.23.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.23.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.23.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.23.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.23.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.23.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.23.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.23.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.23.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.23.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.23.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.23.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.23.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.23.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.23.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.23.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "merging expert 2 to model.layers.23.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.23.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.23.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.23.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.23.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.23.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.23.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.23.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.23.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.23.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.23.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.23.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.23.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.23.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.23.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.23.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.23.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "merging expert 7 to model.layers.23.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.23.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.23.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.23.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.23.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.23.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.23.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.23.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.23.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.23.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.23.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.23.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.23.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00015-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.23.moe.router.weight\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00024.safetensors\n",
      "starting layer: 24\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "merging expert 0 to model.layers.24.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.24.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.24.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00025.safetensors\n",
      "starting layer: 25\n",
      "Loading Tensors  model-00017-of-00021.safetensors\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "merging expert 0 to model.layers.25.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.25.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.25.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.25.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.25.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.25.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00017-of-00021.safetensors\n",
      "merging expert 10 to model.layers.25.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.25.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.25.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.25.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.25.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.25.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.25.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.25.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.25.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.25.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.25.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.25.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.25.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.25.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.25.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.25.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.25.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.25.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.25.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.25.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.25.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.25.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "merging expert 2 to model.layers.25.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.25.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00017-of-00021.safetensors\n",
      "merging expert 2 to model.layers.25.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.25.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.25.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.25.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.25.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.25.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.25.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.25.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.25.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.25.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.25.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.25.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.25.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.25.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.25.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.25.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.25.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.25.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.25.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.25.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.25.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.25.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.25.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.25.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.25.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.25.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.25.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.25.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00016-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.25.moe.router.weight\n",
      "Loading Tensors  model-00017-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00026.safetensors\n",
      "starting layer: 26\n",
      "Loading Tensors  model-00018-of-00021.safetensors\n",
      "Loading Tensors  model-00017-of-00021.safetensors\n",
      "Loading Tensors  model-00018-of-00021.safetensors\n",
      "merging expert 0 to model.layers.26.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.26.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.26.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00027.safetensors\n",
      "starting layer: 27\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "Loading Tensors  model-00018-of-00021.safetensors\n",
      "merging expert 0 to model.layers.27.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.27.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.27.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.27.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.27.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.27.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.27.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.27.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.27.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.27.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.27.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.27.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.27.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.27.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.11.up_proj.weight\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "merging expert 12 to model.layers.27.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "Loading Tensors  model-00018-of-00021.safetensors\n",
      "merging expert 12 to model.layers.27.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "merging expert 12 to model.layers.27.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.27.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.27.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.27.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.27.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.27.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.27.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.27.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.27.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.27.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.27.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.27.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00018-of-00021.safetensors\n",
      "merging expert 2 to model.layers.27.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.27.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.27.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.27.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.27.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.27.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.27.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.27.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.27.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.27.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.27.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.27.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.27.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.27.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.27.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.27.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.27.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.27.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.27.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.27.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.27.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.27.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.27.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.27.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.27.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.27.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.27.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.27.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.27.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.27.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.27.moe.router.weight\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00028.safetensors\n",
      "starting layer: 28\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "merging expert 0 to model.layers.28.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.28.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.28.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00029.safetensors\n",
      "starting layer: 29\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "merging expert 0 to model.layers.29.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.29.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.29.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.29.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.29.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.29.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "merging expert 10 to model.layers.29.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.29.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.29.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.29.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.29.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.29.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.29.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.29.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.29.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.29.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.29.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.29.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.29.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.29.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.29.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.29.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.29.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.29.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.29.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.29.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.29.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.29.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "merging expert 2 to model.layers.29.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.29.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.29.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.29.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.29.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.29.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.29.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.29.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.3.up_proj.weight\n",
      "merging expert 4 to model.layers.29.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 4 to model.layers.29.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 4 to model.layers.29.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.29.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.29.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.29.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.29.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.29.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.29.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.29.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.29.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.29.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.29.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.29.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.29.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.29.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.29.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.29.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "merging expert 8 to model.layers.29.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.29.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.29.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.29.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00019-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.29.moe.router.weight\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00030.safetensors\n",
      "starting layer: 30\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "merging expert 0 to model.layers.30.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.30.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.30.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00031.safetensors\n",
      "starting layer: 31\n",
      "Loading Tensors  model-00021-of-00021.safetensors\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "merging expert 0 to model.layers.31.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 0 to model.layers.31.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 0 to model.layers.31.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.31.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 1 to model.layers.31.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 1 to model.layers.31.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00021-of-00021.safetensors\n",
      "merging expert 10 to model.layers.31.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 10 to model.layers.31.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 10 to model.layers.31.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 11 to model.layers.31.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.31.moe.experts.2.down_proj.weight torch.Size([4096, 14336]) from model.layers.31.moe.experts.11.down_proj.weight\n",
      "merging expert 11 to model.layers.31.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.2.gate_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.11.gate_proj.weight\n",
      "merging expert 11 to model.layers.31.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.2.up_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.11.up_proj.weight\n",
      "merging expert 12 to model.layers.31.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 12 to model.layers.31.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 12 to model.layers.31.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.31.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 13 to model.layers.31.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 13 to model.layers.31.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.31.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 14 to model.layers.31.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 14 to model.layers.31.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 15 to model.layers.31.moe.experts.3.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.31.moe.experts.3.down_proj.weight torch.Size([4096, 14336]) from model.layers.31.moe.experts.15.down_proj.weight\n",
      "merging expert 15 to model.layers.31.moe.experts.3.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.3.gate_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.15.gate_proj.weight\n",
      "merging expert 15 to model.layers.31.moe.experts.3.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.3.up_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.15.up_proj.weight\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "merging expert 2 to model.layers.31.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 2 to model.layers.31.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 2 to model.layers.31.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 3 to model.layers.31.moe.experts.0.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.31.moe.experts.0.down_proj.weight torch.Size([4096, 14336]) from model.layers.31.moe.experts.3.down_proj.weight\n",
      "merging expert 3 to model.layers.31.moe.experts.0.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.0.gate_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.3.gate_proj.weight\n",
      "merging expert 3 to model.layers.31.moe.experts.0.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.0.up_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.3.up_proj.weight\n",
      "Loading Tensors  model-00021-of-00021.safetensors\n",
      "merging expert 4 to model.layers.31.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "merging expert 4 to model.layers.31.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00021-of-00021.safetensors\n",
      "merging expert 4 to model.layers.31.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.31.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 5 to model.layers.31.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 5 to model.layers.31.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.31.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 6 to model.layers.31.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 6 to model.layers.31.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 7 to model.layers.31.moe.experts.1.down_proj.weight torch.Size([4096, 14336])\n",
      "new experts model.layers.31.moe.experts.1.down_proj.weight torch.Size([4096, 14336]) from model.layers.31.moe.experts.7.down_proj.weight\n",
      "merging expert 7 to model.layers.31.moe.experts.1.gate_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.1.gate_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.7.gate_proj.weight\n",
      "merging expert 7 to model.layers.31.moe.experts.1.up_proj.weight torch.Size([14336, 4096])\n",
      "new experts model.layers.31.moe.experts.1.up_proj.weight torch.Size([14336, 4096]) from model.layers.31.moe.experts.7.up_proj.weight\n",
      "merging expert 8 to model.layers.31.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 8 to model.layers.31.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 8 to model.layers.31.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.31.moe.experts.2.down_proj.weight torch.Size([4096, 14336])\n",
      "merging expert 9 to model.layers.31.moe.experts.2.gate_proj.weight torch.Size([14336, 4096])\n",
      "merging expert 9 to model.layers.31.moe.experts.2.up_proj.weight torch.Size([14336, 4096])\n",
      "Loading Tensors  model-00020-of-00021.safetensors\n",
      "reshape torch.Size([16, 4096]) -> view(4, 4, 4096) -> (4, 4096) model.layers.31.moe.router.weight\n",
      "Loading Tensors  model-00021-of-00021.safetensors\n",
      "Save Tensors  /home/emmanuel/Documents/moe-bamba/models/Jamba-4xMoE_slerp/model-00032.safetensors\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%cd {temp_dir}\n",
    "\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tensor_load(file_name, map_location=None):\n",
    "    tensors = {}\n",
    "    with safe_open(file_name, framework=\"pt\") as f:\n",
    "        for k in f.keys():\n",
    "            tensors[k] = f.get_tensor(k)\n",
    "    return tensors\n",
    "\n",
    "def get_weight_byte_size(weight):\n",
    "\n",
    "    if isinstance(weight, torch.Tensor):\n",
    "        weight_byte_size = weight.nelement() * weight.element_size()\n",
    "    else:\n",
    "        weight_byte_size = sum(p.nelement() * p.element_size() for p in weight.parameters())\n",
    "\n",
    "    return weight_byte_size\n",
    "\n",
    "def merge_tensor(tensorA, tensorB):\n",
    "\n",
    "    t = 0.5\n",
    "\n",
    "    dot = torch.sum(tensorA * tensorB, dim=1)\n",
    "    norm_v0 = torch.norm(tensorA, dim=1)\n",
    "    norm_v1 = torch.norm(tensorB, dim=1)\n",
    "    cos_omega = dot / (norm_v0 * norm_v1)\n",
    "\n",
    "    eps = 1e-6\n",
    "    cos_omega = torch.clamp(cos_omega, -1 + eps, 1 - eps)\n",
    "    omega = torch.acos(cos_omega)\n",
    "\n",
    "    # Slerp\n",
    "    v_t = (torch.sin((1 - t) * omega) / torch.sin(omega)).unsqueeze(1) * tensorA \\\n",
    "          + (torch.sin(t * omega) / torch.sin(omega)).unsqueeze(1) * tensorB\n",
    "\n",
    "    return v_t\n",
    "\n",
    "def compute_total_size(weight_map):\n",
    "    total_size = 0\n",
    "    for key in weight_map.keys():\n",
    "        weight = tensor_load(f\"{save_dir}/{weight_map[key]}\", map_location=\"cpu\")\n",
    "        total_size += get_weight_byte_size(weight[key])\n",
    "    return total_size\n",
    "\n",
    "def merge_model(model_name_or_path, save_dir, num_experts_per_tok=2, num_local_experts=2):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    config_path = f\"{save_dir}/config.json\"\n",
    "    current_num_experts_per_tok = 2\n",
    "    current_num_local_experts = 16\n",
    "    config = None\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "        # if \"num_experts_per_tok\" in config:\n",
    "        #     current_num_experts_per_tok = config[\"num_experts_per_tok\"]\n",
    "        #     print(\"current_num_experts_per_tok\", current_num_experts_per_tok)\n",
    "        # else:\n",
    "        #     ValueError(\"num_experts_per_tok not found in config\")\n",
    "        # if \"num_local_experts\" in config:\n",
    "        #     current_num_local_experts = config[\"num_local_experts\"]\n",
    "        #     print(\"current_num_local_experts\", current_num_local_experts)\n",
    "        # else:\n",
    "        #     ValueError(\"num_local_experts not found in config\")\n",
    "        config[\"num_experts_per_tok\"] = num_experts_per_tok\n",
    "        config[\"num_experts\"] = num_local_experts\n",
    "\n",
    "    divisor = current_num_local_experts // num_local_experts\n",
    "    print(\"Divisor:\", divisor)\n",
    "    # save config\n",
    "    with open(f\"{save_dir}/config.json\", \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "\n",
    "    # weight\n",
    "    weight_map = {}\n",
    "    first_weights = [\"lm_head.weight\", \"model.embed_tokens.weight\", \"model.final_layernorm.weight\"]\n",
    "\n",
    "    # load weight map\n",
    "    bin_index_path = f\"{target_dir}/model.safetensors.index.json\"\n",
    "    with open(bin_index_path, \"r\") as f:\n",
    "        weight_map = json.load(f)[\"weight_map\"]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # load weight map\n",
    "    layers = {}\n",
    "    for key in weight_map.keys():\n",
    "        if key in first_weights:\n",
    "            continue\n",
    "        \n",
    "        # print(\"key\", key)\n",
    "        # keyが\"model.layers.[0-9]+.\"にmatchする場合はlayers_listに追加する\n",
    "        layer_str = re.match(r\"model\\.layers\\.[0-9]+\\.\", key)[0]\n",
    "        if layer_str:\n",
    "            layer_no = re.findall(r\"\\d+\",layer_str)\n",
    "            layer_no = layer_no[0]\n",
    "            if layer_no not in layers.keys():\n",
    "                layers[layer_no] = []\n",
    "\n",
    "            layers[layer_no].append({ \"key\":key, \"file_name\":weight_map[key] })\n",
    "\n",
    "    # new weight_map index\n",
    "    new_weight_map = {\n",
    "    \"metadata\": {\n",
    "        \"total_size\": 0\n",
    "    },\n",
    "    \"weight_map\": {\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # load tensors\n",
    "    tensor_weights = {}\n",
    "    tensors = {}\n",
    "    current_file_name = \"\"\n",
    "\n",
    "    file_count = 0\n",
    "    file_count_str = str(file_count).zfill(5)\n",
    "\n",
    "    for key in first_weights:\n",
    "        file_name = weight_map[key]\n",
    "        if current_file_name != file_name:\n",
    "\n",
    "            # load safetensor\n",
    "            tensors = tensor_load(f\"{target_dir}/{file_name}\", map_location=\"cpu\")\n",
    "            current_file_name = file_name\n",
    "\n",
    "        tensor_weights[key] = tensors[key]\n",
    "        new_weight_map[\"weight_map\"][key] = f\"model-{file_count_str}.safetensors\"\n",
    "\n",
    "    # save tensor\n",
    "    save_file(tensor_weights, f\"{save_dir}/model-{file_count_str}.safetensors\", metadata={\"format\":\"pt\"})\n",
    "    file_count += 1\n",
    "\n",
    "    layer_keys = sorted([ int(k) for k in layers.keys()])\n",
    "    print(\"num_layer_keys\", len(layer_keys))\n",
    "    for layer_no in layer_keys:\n",
    "        print(\"starting layer:\",layer_no)\n",
    "        file_count_str = str(file_count).zfill(5)\n",
    "        tensor_weights = {}\n",
    "\n",
    "        stock_expert_weights = {}\n",
    "\n",
    "        current_file_name = \"\"\n",
    "        for info in layers[str(layer_no)]:\n",
    "            file_name = info[\"file_name\"]\n",
    "            if current_file_name != file_name:\n",
    "                print(\"Loading Tensors \", file_name)\n",
    "                tensors = tensor_load(f\"{target_dir}/{file_name}\", map_location=\"cpu\")\n",
    "                current_file_name = file_name\n",
    "\n",
    "            layer_key = info[\"key\"]\n",
    "            layer_weights = tensors[layer_key]\n",
    "\n",
    "            if '.moe.experts' in layer_key:\n",
    "                \n",
    "\n",
    "                lk = re.findall(r\"[.]experts[.][0-9]+.\", layer_key)[0]\n",
    "                exp_index = int( re.findall(r\"\\d+\",lk)[0] )\n",
    "\n",
    "                new_layer_key = re.sub(r\"\\.experts\\.\\d+\\.\", f\".experts.{exp_index // divisor}.\", layer_key)\n",
    "\n",
    "                if new_layer_key not in stock_expert_weights.keys():\n",
    "                    tensor_weights[new_layer_key] = layer_weights\n",
    "                    new_weight_map[\"weight_map\"][new_layer_key] = f\"model-{file_count_str}.safetensors\"\n",
    "                else:\n",
    "                    # merge experts\n",
    "                    tensor_weights[new_layer_key] = merge_tensor(tensor_weights[layer_key] , layer_weights)\n",
    "\n",
    "                print(\"merging expert\", exp_index, \"to\", new_layer_key, tensor_weights[new_layer_key].shape)\n",
    "\n",
    "                if exp_index % divisor == divisor - 1:\n",
    "                    print(\"new experts\", new_layer_key, tensor_weights[new_layer_key].shape, \"from\", layer_key)\n",
    "\n",
    "\n",
    "            elif '.moe.router' in layer_key:\n",
    "                # print(\"reshape\", layer_weights.shape, \"-> view(2, 4, 4096) -> (2, 4096)\", layer_key)\n",
    "                print(\"reshape\", layer_weights.shape, f\"-> view({num_local_experts}, {divisor}, 4096) -> ({num_local_experts}, 4096)\", layer_key)\n",
    "\n",
    "                # calc gate merge\n",
    "                weights_reshaped = layer_weights.view(num_local_experts, divisor, 4096)\n",
    "\n",
    "                for i in range(divisor):\n",
    "                    if i == 0:\n",
    "                        tensor_weights[layer_key] = weights_reshaped[:, i, :]\n",
    "                        new_weight_map[\"weight_map\"][layer_key] = f\"model-{file_count_str}.safetensors\"\n",
    "                    else:\n",
    "                        tensor_weights[layer_key] = merge_tensor(tensor_weights[layer_key], weights_reshaped[:, i, :])\n",
    "\n",
    "\n",
    "            else:\n",
    "                tensor_weights[layer_key] = layer_weights\n",
    "\n",
    "                new_weight_map[\"weight_map\"][layer_key] = f\"model-{file_count_str}.safetensors\"\n",
    "\n",
    "        # save tensor\n",
    "        save_file(tensor_weights, f\"{save_dir}/model-{file_count_str}.safetensors\", metadata={\"format\":\"pt\"})\n",
    "        print(\"Save Tensors \", f\"{save_dir}/model-{file_count_str}.safetensors\")\n",
    "        file_count += 1\n",
    "\n",
    "    # save new_weight_map\n",
    "    new_weight_map[\"metadata\"][\"total_size\"] = compute_total_size(new_weight_map[\"weight_map\"])\n",
    "    with open(f\"{save_dir}/model.safetensors.index.json\", \"w\") as f:\n",
    "        json.dump(new_weight_map, f, indent=2)\n",
    "\n",
    "\n",
    "merge_model(model_name_or_path, save_dir, num_experts_per_tok=2, num_local_experts=8)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
